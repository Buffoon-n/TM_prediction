---
alg: gatlstm
base_dir: logs/pretrained/Abilene
log_level: INFO
gpu: 0
mon_ratio: 0.5
scaler: MM
seed: 1
data:
  data_name: Abilene
  batch_size: 128
  dataset_dir: Dataset/Abilene2d.npy
  adj_method: OD
  day_size: 288
  data_size: 1.0
model:
  input_dim: 5
  num_nodes: 144
  num_rnn_layers: 1
  output_dim: 1
  classif_loss: mse
  optimizer: adam
  learning_rate: 0.001
  max_grad_norm: 1
  n_heads: [8, 1]
  hid_units: [64]
  residual: True
train:
  base_lr: 0.001
  dropout: 0.5
  epoch: 0
  epochs: 50000
  epsilon: 0.00000001
  global_step: 24375
  lr_decay_ratio: 0.05
  max_to_keep: 300
  min_learning_rate: 0.0001
  patience: 50
test:
  run_times: 50
  flow_selection: Random