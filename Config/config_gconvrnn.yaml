---
alg: gconvrnn
base_dir: logs/pretrained/Abilene
log_level: INFO
gpu: 1
mon_ratio: 0.5
scaler: MM
seed: 1
data:
  data_name: Abilene
  batch_size: 256
  test_batch_size: 1
  dataset_dir: Dataset/
  adj_method: OD
  day_size: 288
  data_size: 1.0
model:
  model_type: glstm
  cl_decay_steps: 2000
  filter_type: dual_random_walk
  horizon: 1
  input_dim: 2
  l1_decay: 0
  max_diffusion_step: 1
  num_nodes: 144
  num_rnn_layers: 1
  output_dim: 1
  rnn_units: 256
  seq_len: 36
  num_kernel: 1
  classif_loss: mse
  optimizer: adam
  learning_rate: 0.001
  max_grad_norm: 1
  return_seq: False
train:
  base_lr: 0.005
  dropout: 0.5
  epoch: 0
  epochs: 50000
  epsilon: 0.00000001
  global_step: 24375
  lr_decay_ratio: 0.05
  max_to_keep: 300
  min_learning_rate: 0.0005
  patience: 30
  steps:
    - 50
    - 100
    - 150
    - 200
  logstep: 20
  checkpoint_secs: 300
test:
  run_times: 50
  flow_selection: Random